{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39bed7a0-84b5-494f-9d51-9ea54a3ee73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfe0f07-40bd-4145-bc2d-9973794ba74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load & Clean Data\n",
    "def load_and_clean_data(filepath, ticker):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[3:].reset_index(drop=True)\n",
    "    df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "    df.insert(1, \"Ticker\", ticker)\n",
    "    df[\"Open\"] = df[\"Open\"].astype(float)\n",
    "    df[\"High\"] = df[\"High\"].astype(float)\n",
    "    df[\"Low\"] = df[\"Low\"].astype(float)\n",
    "    df[\"Close\"] = df[\"Close\"].astype(float)\n",
    "    df[\"Volume\"] = df[\"Volume\"].astype(int)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1374d3-2dc5-45d4-ae10-4b14e9cc72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Preprocessing: Moving Averages\n",
    "def add_moving_averages(df):\n",
    "    df[\"MA7\"] = df[\"Close\"].rolling(window=7).mean()\n",
    "    df[\"MA30\"] = df[\"Close\"].rolling(window=30).mean()\n",
    "    return df\n",
    "\n",
    "### 3. ADF Test\n",
    "def adf_test(series):\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    output = pd.Series(result[:4], index=['ADF Statistic', 'p-value', '# Lags Used', 'Number of Observations'])\n",
    "    for key, value in result[4].items():\n",
    "        output[f'Critical Value ({key})'] = value\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26224e40-c498-44c1-89e0-59d40b55b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a. ARIMA Data Prep\n",
    "def prepare_arima_data(df):\n",
    "    df_arima = df[[\"Close\"]].copy()\n",
    "    df_arima[\"Close_diff\"] = df_arima[\"Close\"].diff()\n",
    "    df_arima.dropna(inplace=True)\n",
    "    return df_arima\n",
    "\n",
    "### 4b. ARIMAX Data Prep\n",
    "def prepare_arimax_data(df):\n",
    "    df_arimax = df[[\"Close\", \"MA7\", \"MA30\", \"Volume\"]].copy()\n",
    "    df_arimax.dropna(inplace=True)\n",
    "    return df_arimax\n",
    "\n",
    "### 4c. LSTM Data Prep\n",
    "def prepare_lstm_data(df, lookback=60):\n",
    "    df_lstm = df[[\"Close\"]].copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    df_lstm[\"Scaled_Close\"] = scaler.fit_transform(df_lstm[[\"Close\"]])\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(df_lstm)):\n",
    "        X.append(df_lstm[\"Scaled_Close\"].iloc[i - lookback:i].values)\n",
    "        y.append(df_lstm[\"Scaled_Close\"].iloc[i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb782186-a1d7-4de3-8165-e7ceb1cbc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Train-Test Split\n",
    "def split_data(data, train_ratio=0.8):\n",
    "    split = int(len(data) * train_ratio)\n",
    "    return data[:split], data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f440fe-0050-4888-9352-7487a24c7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6a. Train ARIMA Model\n",
    "def train_arima(train_data, test_data):\n",
    "    model = ARIMA(train_data[\"Close\"], order=(1, 1, 1))\n",
    "    model_fit = model.fit()\n",
    "    pred = model_fit.forecast(steps=len(test_data))\n",
    "    return pred, model_fit\n",
    "\n",
    "### 6b. Train ARIMAX Model\n",
    "def train_arimax(train_data, test_data):\n",
    "    model = SARIMAX(train_data[\"Close\"], exog=train_data[[\"Volume\", \"MA7\", \"MA30\"]], order=(1, 1, 1))\n",
    "    model_fit = model.fit()\n",
    "    pred = model_fit.forecast(steps=len(test_data), exog=test_data[[\"Volume\", \"MA7\", \"MA30\"]])\n",
    "    return pred, model_fit\n",
    "\n",
    "### 6c. Train LSTM Model\n",
    "def train_lstm(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=16,\n",
    "                        validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)\n",
    "    pred = model.predict(X_test)\n",
    "    return pred, model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32ec2281-4cd6-4cce-8f31-b8a8fa22375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Evaluation\n",
    "def evaluate_model(true_values, predicted_values, label=\"Model\"):\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    rmse = mean_squared_error(true_values, predicted_values, squared=False)\n",
    "    r2 = r2_score(true_values, predicted_values)\n",
    "\n",
    "    print(f\"{label} MAE: {mae}\")\n",
    "    print(f\"{label} RMSE: {rmse}\")\n",
    "    print(f\"{label} R² Score: {r2}\")\n",
    "    return mae\n",
    "\n",
    "### 8. Plotting Functions\n",
    "def plot_predictions(index, actual, predicted, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(index, actual, label=\"Actual\", color=\"green\")\n",
    "    plt.plot(index, predicted, label=\"Predicted\", color=\"red\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', color='orange')\n",
    "    plt.title(\"Training & Validation Loss Curve\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be45e650-c99a-4ba6-b09d-7bc3b8cc0322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Processing MSFT =================\n",
      "ARIMA MAE: 28.079933150379446\n",
      "ARIMA RMSE: 31.03484748773525\n",
      "ARIMA R² Score: -1.688279222303784\n",
      "ARIMAX MAE: 5.835796814140705\n",
      "ARIMAX RMSE: 7.52511489094235\n",
      "ARIMAX R² Score: 0.7597101307483876\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 250ms/step - loss: 0.1852 - val_loss: 0.0758\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 0.0330 - val_loss: 0.0296\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0316 - val_loss: 0.0412\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0286 - val_loss: 0.0427\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 0.0276 - val_loss: 0.0381\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0275 - val_loss: 0.0454\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0227 - val_loss: 0.0385\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883ms/step\n",
      "LSTM MAE: 13.904001871744798\n",
      "LSTM RMSE: 15.389154082938065\n",
      "LSTM R² Score: -0.6875864651722701\n",
      "\n",
      "================= Processing AAPL =================\n",
      "ARIMA MAE: 9.26556400424164\n",
      "ARIMA RMSE: 10.528027529828767\n",
      "ARIMA R² Score: -0.0003766582755624359\n",
      "ARIMAX MAE: 6.805728373493543\n",
      "ARIMAX RMSE: 8.496791266679976\n",
      "ARIMAX R² Score: 0.38964520062249375\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - loss: 0.2413 - val_loss: 0.0249\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - loss: 0.0187 - val_loss: 0.0139\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0149 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0152 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0179 - val_loss: 0.0200\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 882ms/step\n",
      "LSTM MAE: 8.565979786408256\n",
      "LSTM RMSE: 10.760820016181144\n",
      "LSTM R² Score: 0.11393546306016722\n",
      "\n",
      "================= Processing NVDA =================\n",
      "ARIMA MAE: 14.860485997166792\n",
      "ARIMA RMSE: 17.14698300775454\n",
      "ARIMA R² Score: -1.5334391229353788\n",
      "ARIMAX MAE: 13.283310799829794\n",
      "ARIMAX RMSE: 14.345346266252468\n",
      "ARIMAX R² Score: -1.3660589303355137\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - loss: 0.3259 - val_loss: 0.0368\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0316 - val_loss: 0.0152\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - loss: 0.0237 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0264 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0220 - val_loss: 0.0178\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.0272 - val_loss: 0.0207\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0219 - val_loss: 0.0243\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892ms/step\n",
      "LSTM MAE: 7.5412576137444916\n",
      "LSTM RMSE: 9.024240889937033\n",
      "LSTM R² Score: 0.16677925432350038\n",
      "\n",
      "================= Processing AMZN =================\n",
      "ARIMA MAE: 17.210754183246205\n",
      "ARIMA RMSE: 20.34615454185811\n",
      "ARIMA R² Score: -0.4135441185364983\n",
      "ARIMAX MAE: 6.5951832667465435\n",
      "ARIMAX RMSE: 7.498513957323687\n",
      "ARIMAX R² Score: 0.7999172054862304\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - loss: 0.1542 - val_loss: 0.1385\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0322 - val_loss: 0.0155\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.0247 - val_loss: 0.0415\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 0.0181 - val_loss: 0.0255\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0187 - val_loss: 0.0382\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0179 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0166 - val_loss: 0.0358\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 856ms/step\n",
      "LSTM MAE: 8.49656520745693\n",
      "LSTM RMSE: 10.090542745660835\n",
      "LSTM R² Score: 0.5300585101850583\n",
      "\n",
      "================= Processing TSLA =================\n",
      "ARIMA MAE: 110.21553482495057\n",
      "ARIMA RMSE: 126.40288686500809\n",
      "ARIMA R² Score: -3.171466731917863\n",
      "ARIMAX MAE: 13.08454685129608\n",
      "ARIMAX RMSE: 17.196735232498902\n",
      "ARIMAX R² Score: 0.9057710339280587\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 251ms/step - loss: 0.1081 - val_loss: 0.0553\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - loss: 0.0212 - val_loss: 0.0410\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0156 - val_loss: 0.0360\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0128 - val_loss: 0.0519\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0131 - val_loss: 0.0243\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - loss: 0.0118 - val_loss: 0.0421\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0124 - val_loss: 0.0391\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 0.0108 - val_loss: 0.0389\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 0.0108 - val_loss: 0.0231\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0108 - val_loss: 0.0427\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863ms/step\n",
      "LSTM MAE: 44.31513468424479\n",
      "LSTM RMSE: 51.30677751371398\n",
      "LSTM R² Score: -0.1905906341952719\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tickers = [\"MSFT\", \"AAPL\", \"NVDA\", \"AMZN\", \"TSLA\"]  # Add your tickers here\n",
    "\n",
    "    for ticker in tickers:\n",
    "        print(f\"\\n================= Processing {ticker} =================\")\n",
    "\n",
    "        # === Load and clean data ===\n",
    "        filepath = f\"C:/Users/Shush/Final_Sem_Project/Stocks_Data/{ticker}_data.csv\"\n",
    "        df = load_and_clean_data(filepath, ticker)\n",
    "        df = add_moving_averages(df)\n",
    "\n",
    "        model_mae_scores = {}\n",
    "\n",
    "        # === ARIMA ===\n",
    "        df_arima = prepare_arima_data(df)\n",
    "        train_arima_df, test_arima_df = split_data(df_arima)\n",
    "        arima_pred, arima_model = train_arima(train_arima_df, test_arima_df)\n",
    "        arima_mae = evaluate_model(test_arima_df[\"Close\"], arima_pred, \"ARIMA\")\n",
    "        model_mae_scores[\"ARIMA\"] = (arima_mae, arima_model)\n",
    "\n",
    "        # === ARIMAX ===\n",
    "        df_arimax = prepare_arimax_data(df)\n",
    "        train_arimax_df, test_arimax_df = split_data(df_arimax)\n",
    "        arimax_pred, arimax_model = train_arimax(train_arimax_df, test_arimax_df)\n",
    "        arimax_mae = evaluate_model(test_arimax_df[\"Close\"], arimax_pred, \"ARIMAX\")\n",
    "        model_mae_scores[\"ARIMAX\"] = (arimax_mae, arimax_model)\n",
    "\n",
    "        # === LSTM ===\n",
    "        lookback = 60\n",
    "        X, y, scaler = prepare_lstm_data(df, lookback)\n",
    "        X_train, X_test = split_data(X)\n",
    "        y_train, y_test = split_data(y)\n",
    "        lstm_pred_scaled, lstm_model, lstm_history = train_lstm(X_train, y_train, X_test, y_test)\n",
    "        lstm_pred = scaler.inverse_transform(lstm_pred_scaled)\n",
    "        y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "        lstm_mae = evaluate_model(y_test_unscaled, lstm_pred, \"LSTM\")\n",
    "        model_mae_scores[\"LSTM\"] = (lstm_mae, lstm_model)\n",
    "        \n",
    "        joblib.dump(best_model, f\"{ticker}_arimax_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca69ba5-a485-432f-ba72-0e8a420998f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
